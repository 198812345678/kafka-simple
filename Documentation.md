### 4. DESIGN
#### 4.2 Persistence
##### Don't fear the filesystem!
* kafka使用文件作为存储
* 基于kafka数据量比较大的应用场景，使用内存有两个缺点，1.数据对象占用内存大；2.GC过程复杂，比较耗时
* 操作系统实现的文件系统在磁盘和内核之间也有缓存，并且更加可靠
* 因此kafka选择使用文件log方式持久化，数据会利用文件系统在内核的缓存机制
##### Constant Time Suffices
* 消息系统中数据持久化的数据结构有可能是使用B数，访问B树的时间复杂度理论上是常量，但是磁盘操作在一定维度上控制并行，开销很大
* 将磁盘操作和缓存操作结合，这样的性能是随数据量的增长呈线性增长的
* log方式持久化数据直观点就是，只对文件进行追加和读取（TODO 顺序读取？），读写并行，并且可以水平扩展
* 这样kafka的数据容量就更大，持久化的数据更多
#### 4.3 Efficiency
* 如果少量应用就能使基础设施成为瓶颈，那么很小的变化就可能造成问题
* 提高基础设施的效率能保证应用负载过重之前基础设施没有问题，这在集群部署方式中非常重要，因为集群上部署着几十上百的应用，相互影响很危险
* 除了磁盘还有两个影响性能的因素：1.频繁的小数据量I/O操作，2.大量的数据拷贝
* 为了避免频繁的小数据量I/O操作，kafka将消息打包，一组消息平摊一次I/O操作的开销，server端一次追加一组数据到log，consumer一次fetch一组数据
* 打包消息的方式将速度提升几个数量级，更多的顺序磁盘操作，连续的内存块等，尽量将数据的随机访问转化为顺序访问
* 低负载场景下数据拷贝问题不大，高负载场景影响比较大，kafka中的数据在producer，broker，consumer之间是以二进制形式流转，流转的时候不需要转换(可以直接利用零拷贝机制传输)
* broker维护的二进制数据就是一个文件，文件里的数据可以利用领拷贝机制减少传输开销
* 普通网络传输文件数据的方式是，1.数据从磁盘拷贝到内核的pagecache，2.应用从内核把数据拷贝到用户空间的buffer，3.应用把数据写道内核的socket buffer，4.操作系统把数据从socket buffer拷贝到网卡的buffer
* 上述流程需要4次数据拷贝，2次系统调用，但是sendfile机制直接把数据从pagecache拷贝到网卡buffer
* 假设多数场景是多个consumer从同一个topic消费数据，利用上述的零拷贝机制，数据读取一次缓存在pagecache，避免了内存中存储数据，也不用在内核和用户空间之间拷贝数据，约等于不用拷贝数据，只是网络开销
* 在消费者比较多的场景，上述机制基本不用从磁盘读取数据
##### End-to-end Batch Compression
* 网络之间传输压缩后的数据能节省带宽，压缩算法对重复内容压缩效果明显，多个消息中大部分字段名是重复的，因此批量压缩消息比单个消息压缩效果好

> 线性访问磁盘比随机访问内存快
> 如果使用缓存，需要